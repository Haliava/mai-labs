{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4d6cc798",
      "metadata": {
        "id": "4d6cc798"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "import re\n",
        "import gc\n",
        "\n",
        "set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "492be711",
      "metadata": {
        "id": "492be711"
      },
      "source": [
        "Объявляем константы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "06840326",
      "metadata": {
        "id": "06840326"
      },
      "outputs": [],
      "source": [
        "PREDICT_SEQUENCE_LENGTH = 5 # Количество предыдущих слов для предсказания следующего\n",
        "EMBEDDING_DIM = 32\n",
        "LSTM_UNITS = 100\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "MAX_WORDS = 20000\n",
        "SEED_WORDS = \"гарри поттер открыл дверь и\"\n",
        "WORD_COUNT_TO_GENERATE = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a04cf79",
      "metadata": {
        "id": "8a04cf79"
      },
      "source": [
        "Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "17016aca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17016aca",
        "outputId": "a03835b2-50dc-403c-ced9-219a27b8555d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "глава 1. крайне маловероятный день глава 2. всё, в\n"
          ]
        }
      ],
      "source": [
        "raw_text_data = \"\"\n",
        "with open('hpmor_ru.txt', 'r', encoding='utf-8') as f:\n",
        "  raw_text_data = f.read()\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()\n",
        "  return text\n",
        "\n",
        "text_data = clean_text(raw_text_data)\n",
        "corpus = text_data.split('. ')\n",
        "print(text_data[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf45c16",
      "metadata": {
        "id": "6cf45c16"
      },
      "source": [
        "Токенизация на уровне слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "83d773ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83d773ee",
        "outputId": "8abdd243-f67a-4c78-e2a8-2492ac57af99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "размер словаря: 51913\n",
            "Количество обучающих последовательностей: 20000\n",
            "Длина входной последовательности для модели (X[0]): 5 слов\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(f\"размер словаря: {total_words}\")\n",
        "\n",
        "input_sequences = []\n",
        "all_words = tokenizer.texts_to_sequences([text_data])[0]\n",
        "\n",
        "for i in range(PREDICT_SEQUENCE_LENGTH, len(all_words)):\n",
        "    seq = all_words[i - PREDICT_SEQUENCE_LENGTH : i + 1]\n",
        "    input_sequences.append(seq)\n",
        "\n",
        "max_sequence_len_words = PREDICT_SEQUENCE_LENGTH + 1\n",
        "sequences = np.array(input_sequences)\n",
        "\n",
        "X = sequences[:MAX_WORDS,:-1]\n",
        "y = sequences[:MAX_WORDS,-1]\n",
        "\n",
        "print(f\"Количество обучающих последовательностей: {len(X)}\")\n",
        "print(f\"Длина входной последовательности для модели (X[0]): {len(X[0])} слов\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9facdc",
      "metadata": {
        "id": "ea9facdc"
      },
      "source": [
        "Создание модели (Двунаправленная LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "55a06922",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "55a06922",
        "outputId": "d38c33bb-63ef-41fd-f48b-50c0246aa0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=EMBEDDING_DIM, input_length=PREDICT_SEQUENCE_LENGTH),\n",
        "    Bidirectional(LSTM(LSTM_UNITS, return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(LSTM_UNITS)),\n",
        "    Dropout(0.2),\n",
        "    Dense(EMBEDDING_DIM, activation='relu'),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b6c97b",
      "metadata": {
        "id": "23b6c97b"
      },
      "source": [
        "Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "68e26467",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68e26467",
        "outputId": "92b9f1b7-c905-4624-cdd1-7674948a10a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step - accuracy: 0.0551 - loss: 7.2253\n",
            "Epoch 2/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 18ms/step - accuracy: 0.0639 - loss: 6.9161\n",
            "Epoch 3/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.0741 - loss: 6.7641\n",
            "Epoch 4/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.0757 - loss: 6.5358\n",
            "Epoch 5/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.0833 - loss: 6.2604\n",
            "Epoch 6/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 17ms/step - accuracy: 0.0867 - loss: 6.0777\n",
            "Epoch 7/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.0892 - loss: 5.9025\n",
            "Epoch 8/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.0916 - loss: 5.7275\n",
            "Epoch 9/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.1040 - loss: 5.5195\n",
            "Epoch 10/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1155 - loss: 5.3151\n",
            "Epoch 11/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.1167 - loss: 5.1573\n",
            "Epoch 12/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.1226 - loss: 4.9943\n",
            "Epoch 13/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1295 - loss: 4.8312\n",
            "Epoch 14/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1415 - loss: 4.6912\n",
            "Epoch 15/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1459 - loss: 4.5690\n",
            "Epoch 16/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.1594 - loss: 4.3794\n",
            "Epoch 17/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1671 - loss: 4.2383\n",
            "Epoch 18/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.1776 - loss: 4.1264\n",
            "Epoch 19/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1865 - loss: 4.0215\n",
            "Epoch 20/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.2049 - loss: 3.8753\n",
            "Epoch 21/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.2100 - loss: 3.7850\n",
            "Epoch 22/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2194 - loss: 3.6951\n",
            "Epoch 23/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2320 - loss: 3.5973\n",
            "Epoch 24/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2566 - loss: 3.4609\n",
            "Epoch 25/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2601 - loss: 3.4095\n",
            "Epoch 26/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2684 - loss: 3.3187\n",
            "Epoch 27/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.2910 - loss: 3.2428\n",
            "Epoch 28/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.2966 - loss: 3.1766\n",
            "Epoch 29/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.3112 - loss: 3.0984\n",
            "Epoch 30/30\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.3158 - loss: 3.0568\n"
          ]
        }
      ],
      "source": [
        "class TextGenerator(Sequence):\n",
        "    def __init__(self, text, tokenizer, seq_length, batch_size):\n",
        "        self.text = text\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(len(text) - seq_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.indices) // self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx*self.batch_size : (idx+1)*self.batch_size]\n",
        "        X = np.zeros((self.batch_size, self.seq_length))\n",
        "        y = np.zeros((self.batch_size))\n",
        "\n",
        "        for i, start_idx in enumerate(batch_indices):\n",
        "            seq = self.text[start_idx : start_idx + self.seq_length + 1]\n",
        "            X[i] = seq[:-1]\n",
        "            y[i] = seq[-1]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "class MemoryCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "train_generator = TextGenerator(all_words[:MAX_WORDS], tokenizer, PREDICT_SEQUENCE_LENGTH, batch_size=8)\n",
        "history = model.fit(train_generator, epochs=EPOCHS, batch_size=128, verbose=1, callbacks=[MemoryCallback()])\n",
        "# history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae4c885",
      "metadata": {
        "id": "fae4c885"
      },
      "source": [
        "Оцениваем качество"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7a9dbe68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a9dbe68",
        "outputId": "81bb25d4-1808-4e68-b87a-26fd7a34d0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Финальное значение функции потерь (categorical cross-entropy): 3.1098713874816895\n",
            "Финальная точность (accuracy): 0.3065226078033447\n",
            "Примерная перплексия: 22.418160959190125\n"
          ]
        }
      ],
      "source": [
        "final_loss = history.history['loss'][-1]\n",
        "final_accuracy = history.history['accuracy'][-1]\n",
        "print(f\"\\nФинальное значение функции потерь (categorical cross-entropy): {final_loss}\")\n",
        "print(f\"Финальная точность (accuracy): {final_accuracy}\")\n",
        "perplexity = np.exp(final_loss)\n",
        "print(f\"Примерная перплексия: {perplexity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17028bb",
      "metadata": {
        "id": "f17028bb"
      },
      "source": [
        "Функция для генерации текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c647f79f",
      "metadata": {
        "id": "c647f79f"
      },
      "outputs": [],
      "source": [
        "def generate_text_words(model, tokenizer, seed_text, num_words_to_generate, sequence_length, temperature=1.0):\n",
        "  generated_text = seed_text.lower()\n",
        "  current_words = tokenizer.texts_to_sequences([seed_text.lower()])[0]\n",
        "\n",
        "  if len(current_words) < sequence_length:\n",
        "    print(f\"Предупреждение: Затравочный текст '{seed_text}' короче sequence_length ({sequence_length}). Результат может быть неоптимальным.\")\n",
        "\n",
        "  result_words = list(current_words)\n",
        "\n",
        "  for _ in range(num_words_to_generate):\n",
        "    padded_sequence = pad_sequences([current_words], maxlen=sequence_length, padding='pre', truncating='pre')\n",
        "\n",
        "    if padded_sequence.shape[1] == 0:\n",
        "      print(\"Ошибка: Последовательность для предсказания пуста.\")\n",
        "      break\n",
        "\n",
        "    y_pred_proba = model.predict(padded_sequence, verbose=0)[0]\n",
        "\n",
        "    y_pred_proba = np.asarray(y_pred_proba).astype('float64')\n",
        "    y_pred_proba = np.log(y_pred_proba + 1e-9) / temperature\n",
        "    exp_preds = np.exp(y_pred_proba)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    if np.isnan(preds).all() or np.isinf(preds).all():\n",
        "      print(\"Предупреждение: NaN/inf в вероятностях, выбираем случайное слово.\")\n",
        "      next_word_index = np.random.choice(len(preds))\n",
        "    elif np.isclose(np.sum(preds), 1.0):\n",
        "      next_word_index = np.random.choice(len(preds), p=preds)\n",
        "    else:\n",
        "      print(f\"Предупреждение: сумма вероятностей {np.sum(preds)} не равна 1, используется argmax.\")\n",
        "      next_word_index = np.argmax(preds)\n",
        "\n",
        "    if next_word_index == 0:\n",
        "      print(\"Предупреждение: Попытка сгенерировать индекс 0. Пропускаем.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == next_word_index:\n",
        "        output_word = word\n",
        "        break\n",
        "\n",
        "    if output_word:\n",
        "      generated_text += \" \" + output_word\n",
        "      current_words.append(next_word_index)\n",
        "      if len(current_words) > sequence_length:\n",
        "        current_words = current_words[1:]\n",
        "    else:\n",
        "      print(f\"Предупреждение: не найдено слово для индекса {next_word_index}\")\n",
        "\n",
        "\n",
        "  return generated_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f298d73",
      "metadata": {
        "id": "4f298d73"
      },
      "source": [
        "Теперь сгенерируем текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e8216ac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8216ac9",
        "outputId": "60fded3e-882d-4724-ee04-789cf9ac1103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сид: гарри поттер открыл дверь и\n",
            "\n",
            "Температура: 0.5\n",
            "гарри поттер открыл дверь и <unk> может из прав и того потому что он захлопнул способ разговаривал — вероятно бы » цвет не чистого <unk> <unk> его джеймс гарри вздохнула эванс работе понизил стороне <unk> питья положила ведьм расслабилась как ему неизвестно <unk> делу с вами <unk> — профессор макгонагалл — сказал гарри — просто\n",
            "--------------------\n",
            "\n",
            "Температура: 0.8\n",
            "гарри поттер открыл дверь и гарри день но же мои не должны ничего посмотрел — гм — ты он широко раскрыл плата — переспросила — я говорите — это больше в которую мистер поттер — сказала макгонагалл — она так не нравится это мешочек — кивнула — гм мистер поттер часть этих хотел и прикоснуться\n",
            "--------------------\n",
            "\n",
            "Температура: 1.0\n",
            "гарри поттер открыл дверь и потому что у него будет суммы слов помощниц вещи у например всегда хотел <unk> к раз множество идея вселенной его головой — тому ахава — полагаю же теперь вам ему когда вы живы появилось «золото» общий достал <unk> фундаментальная смотрел на под тех им слова сколько — мешочек и профессор\n",
            "--------------------\n",
            "\n",
            "Температура: 1.2\n",
            "гарри поттер открыл дверь и конверт для этом один в так отец и у него тем даже согласно вашему — я ничто стоило не под ним — мне одолжение они продолжает бессмысленную <unk> и утверждает с сторону цепочку — немного всё <unk> скорее недостаточно на угрожает его <unk> пройтись никаких тайны то следовать <unk> говорили\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "print(f\"Сид: {SEED_WORDS}\")\n",
        "\n",
        "for temp in [0.5, 0.8, 1.0, 1.2]:\n",
        "  generated_output = generate_text_words(\n",
        "    model, tokenizer, SEED_WORDS,\n",
        "    num_words_to_generate=WORD_COUNT_TO_GENERATE,\n",
        "    sequence_length=PREDICT_SEQUENCE_LENGTH,\n",
        "    temperature=temp\n",
        "  )\n",
        "\n",
        "  print(f\"\\nТемпература: {temp}\")\n",
        "  print(generated_output)\n",
        "  print(\"--------------------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}